---
title: "ModelDiag"
author: "Yunsheng Lu"
date: "2023-04-23"
output: html_document
---

```{r}
library(ggplot2)
library(fastDummies)
library(tidyverse)
library(caret)
library(MASS)
# read data ------------------------
math = read.csv("student-mat.csv", sep = ';', stringsAsFactors = T)
str(math)
por = read.csv("student-por.csv", sep = ";", stringsAsFactors = T)
str(por)

#set dummies
math = fastDummies::dummy_columns(math, remove_first_dummy = T, remove_selected_columns = T)
por = fastDummies::dummy_columns(por, remove_first_dummy = T, remove_selected_columns = T)


predictors = setdiff(colnames(math), c("G1", "G2", "G3"))

math$grade.cat = cut(math$G1, breaks=c(-1, 9, 20),
                     labels=c('F','P'))
por$grade.cat = cut(por$G1, breaks=c(-1,9,20),
                    labels=c('F','P'))
por$grade.con = por$G1
math$grade.con = math$G1


# split data -------------------------
set.seed(114514)

preproc.param <- math %>%
  preProcess(method = c("center", "scale"))
math <- preproc.param %>% predict(math)

preproc.param <- por%>%
  preProcess(method = c("center", "scale"))
por<- preproc.param %>% predict(por)

train_idx.math = sample(1:nrow(math), floor(nrow(math))*0.8, replace = F)
train_idx.por = sample(1:nrow(por), floor(nrow(por))*0.8, replace = F)

math.train = math[train_idx.math,]
math.test = math[-train_idx.math,]

por.train = por[train_idx.por,]
por.test = por[-train_idx.por,]
preproc.param <- math.train %>%
  preProcess(method = c("center", "scale"))
math.train <- preproc.param %>% predict(math.train)
math.test <- preproc.param %>% predict(math.test)
preproc.param <- por.train %>%
  preProcess(method = c("center", "scale"))
por.train <- preproc.param %>% predict(por.train)
por.test <- preproc.param %>% predict(por.test)

library(e1071)
classification.formula = as.formula(paste("grade.cat~", paste(predictors, collapse = "+"), sep = ''))
regression.formula = as.formula(paste("grade.con~", paste(predictors, collapse = "+"), sep = ''))
```

Check Multicollinearity
```{r}
library(faraway)
math.ols<-lm(regression.formula,data=math)
summary(math.ols)
#conduct multicollinearity detection
vif(math.ols)
math.mult<-math[,-c(27,28)]
math.ols.mult<-lm(grade.con~.-G1-G2-G3-grade.cat,data=math.mult)
summary(math.ols.mult)
#R^2=0.2595
```
Identifying Outlier
```{r}
library(faraway)
cook.math<-cooks.distance(math.ols.mult)
halfnorm(cook.math,5,ylab="Cook's Distance")
math.mult.out<-math.mult[-c(1,158,193,199,266),]
math.ols.mult.out<-lm(grade.con~.-G1-G2-G3-grade.cat,data=math.mult.out)
summary(math.ols.mult.out)
#R^2=0.2858
```

Check Error Assumption
```{r}
library(MASS)
rn<-rnorm(300,0,1)
par(mfrow=c(1,2))
qqnorm(rn,pch = 1, ylab="normally generated data points",frame = FALSE)
qqnorm(math.ols.mult.out$residuals,pch = 1,ylab="residual of OLS", frame = FALSE)
math.mult.out.error<-math.mult.out
math.mult.out.error$grade.con<-math.mult.out.error$grade.con+4
math.ols.mult.out.error<-lm(grade.con~.-G1-G2-G3-grade.cat,data=math.mult.out.error)
bc<-boxcox(math.ols.mult.out.error,plotit=T)
lambda <- bc$x[which.max(bc$y)]
lambda
math.mult.out.error.sq<-math.mult.out.error
math.mult.out.error.sq$grade.con<-((math.mult.out.error.sq$grade.con)^0.30303-1)/0.30303
math.ols.trans<-lm(grade.con~.-grade.cat-G1-G2-G3,data=math.mult.out.error.sq)
summary(math.ols.trans)
#R^2=0.2987
```

Nonlinearity Detection
```{r}
library(car)
crPlots(math.ols.trans)
```



